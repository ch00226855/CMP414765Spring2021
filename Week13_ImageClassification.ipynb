{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week13_ImageClassification",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdaUHkTPqBsYoe69HMnhQr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ch00226855/CMP414765Spring2021/blob/main/Week13_ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwszdj54lJYI"
      },
      "source": [
        "# Week 13\n",
        "# Image Classification with Convolutional Neural Network (CNN)\n",
        "\n",
        "**Reference:** [TensorFlow Tutorial on Convolutional Neural Networks](https://www.tensorflow.org/tutorials/images/cnn)\n",
        "\n",
        "**Please enable GPU computing before proceed.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlP21Dd3lUmQ"
      },
      "source": [
        "### Ideas\n",
        "- Dense layers may contain redudent connections\n",
        "- Some information should be invariant to spacial translation\n",
        "- The number of parameters can be reduced if certain weights share the same value.\n",
        "\n",
        "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcS4LZdFg5QPbgDb-jvP-YT0N51eRkWg45uF0ybsB5k0Ubr0-gOC&usqp=CAU\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bUdECNflUqJ"
      },
      "source": [
        "## 2D Convolution Layer\n",
        "<img src=\"https://cdn-media-1.freecodecamp.org/images/Gjxh-aApWTzIRI1UNmGnNLrk8OKsQaf2tlDu\" width=\"600\">\n",
        "\n",
        "**Comparison:**\n",
        "If this were a densely connect layer:\n",
        "- The number of connection would be: 64 * 64 = 4096\n",
        "- The number of weight parameters would be: 4096\n",
        "\n",
        "Now that this is a convolutional layer (with a 3*3 filter):\n",
        "- The number of connection is: 9 * 64 = 576\n",
        "- The number of parameters is: 9\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwW4aozplUsh"
      },
      "source": [
        "**2D smoothing with Gaussian kernel**\n",
        "\n",
        "<img src=\"https://www.cs.umd.edu/class/fall2016/cmsc426/matlab/filters/html/filters_tutorial_03.png\" width=\"600\">\n",
        "\n",
        "<img src=\"https://www.mathworks.com/help/examples/stats/win64/ComputeTheMultivariateNormalPdfExample_01.png\" width=\"400\">\n",
        "\n",
        "**Edge detection**\n",
        "\n",
        "<img src=\"https://aishack.in/static/img/tut/conv-line-detection-horizontal-result.jpg\" width=\"400\">\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Ching-Wei_Wang/publication/221472523/figure/fig5/AS:305540338077700@1449857901164/Convolution-filter-for-simple-edge-detect.png\" width=\"200\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLjGZkvdlUuv"
      },
      "source": [
        "## LeNet5 on MNIST\n",
        "\n",
        "Yann LeCun, Leon Bottou, Yosuha Bengio and Patrick Haffner proposed a neural network architecture for handwritten and machine-printed character recognition in 1990â€™s which they called LeNet-5. It is one of the early example of a convolutional neural network\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/4308/1*1TI1aGBZ4dybR6__DI9dzA.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBDLWUMXlUxd"
      },
      "source": [
        "## Max-Pooling Layer\n",
        "<img src=\"https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM3NwmG7lUz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18636fe8-c124-4344-db9f-e671bf90a9e8"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "# import tensorflow.keras as K\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK6gaIZllU22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf2c59b-b011-4035-be00-d849fca1e995"
      },
      "source": [
        "# Load and prepare the MNIST dataset.\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Convert the data from integers to floating-point numbers\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mlo6L7WlU4_"
      },
      "source": [
        "model_cnn = tf.keras.models.Sequential()\n",
        "\n",
        "model_cnn.add(tf.keras.layers.Conv2D(filters=6,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 activation='relu',\n",
        "                                 input_shape=(28, 28, 1)))\n",
        "\n",
        "model_cnn.add(tf.keras.layers.MaxPooling2D())\n",
        "\n",
        "model_cnn.add(tf.keras.layers.Conv2D(filters=16,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 activation='relu'))\n",
        "\n",
        "model_cnn.add(tf.keras.layers.MaxPooling2D())\n",
        "\n",
        "model_cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model_cnn.add(tf.keras.layers.Dense(units=120,\n",
        "                       activation='relu'))\n",
        "model_cnn.add(tf.keras.layers.Dense(units=84,\n",
        "                       activation='relu'))\n",
        "model_cnn.add(tf.keras.layers.Dense(units=10,\n",
        "                       activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k4KnhA7lU7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b3b973-0f3c-48d6-a381-337145e20798"
      },
      "source": [
        "model_cnn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 6)         60        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 16)        880       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               48120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 60,074\n",
            "Trainable params: 60,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un9uUBdPlU9z"
      },
      "source": [
        "model_cnn.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJPG5htRlVAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f2dc2f-2c8f-46ca-d2ba-cbae0935b584"
      },
      "source": [
        "model_cnn.fit(x_train.reshape(list(x_train.shape) + [1]), y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 35s 2ms/step - loss: 0.4327 - accuracy: 0.8762\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0595 - accuracy: 0.9824\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0409 - accuracy: 0.9877\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0299 - accuracy: 0.9902\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0239 - accuracy: 0.9920\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0185 - accuracy: 0.9942\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0154 - accuracy: 0.9948\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0140 - accuracy: 0.9953\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0117 - accuracy: 0.9960\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0108 - accuracy: 0.9965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6bda7a8650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDHmNAYTlVC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4274a072-84a6-4b38-ca28-2e9e3b103a8a"
      },
      "source": [
        "model_cnn.evaluate(x_test.reshape(list(x_test.shape) + [1]), y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0415 - accuracy: 0.9879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.041487112641334534, 0.9879000186920166]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82mo08SBlVFg"
      },
      "source": [
        "## Dropout and Model Regularization\n",
        "For a complicated model like deep neural networks, a major concern on its performance is model overfitting:\n",
        "\n",
        "![underfitting and overfitting](https://cdn-images-1.medium.com/max/1200/1*cdvfzvpkJkUudDEryFtCnA.png)\n",
        "\n",
        "In plain words, overfitting happens when the model is **memorizing** the training data, and become poorly at **generalizing** what they've learned to unseen data. Think about a student who memorized the entire machine learning textbook. He may appear quite knowledgable in machine learning when asked things directly from the book, but there is no way he can perform a machine project on a dataset not mentioned in the book.\n",
        "\n",
        "### How to dentify model overfitting?\n",
        "- Visualize the model (decision boundary, regression curves, etc.)\n",
        "- Observe the trends in training loss and the testing loss\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/1600/1*vuZxFMi5fODz2OEcpG-S1g.png)\n",
        "\n",
        "### How to prevent model overfitting?\n",
        "1. Start with a simple model\n",
        "\n",
        "![](https://image.slidesharecdn.com/lawsofwebdesign-091104020153-phpapp01/95/laws-of-web-development-11-728.jpg?cb=1257384621)\n",
        "2. Add penalty to complicated models\n",
        "    - L1 Regularizor\n",
        "    - L2 Regularizor\n",
        "    - Elastic Net\n",
        "\n",
        "3. (For Neural Networks) Dropout layers: remove weights to the next layer\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/1800/1*iWQzxhVlvadk6VAJjsgXgg.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7C9uja3lVIo"
      },
      "source": [
        "# Image Classification with CIFAR-10 Dataset\n",
        "[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) is a widely used benchmark dataset for image classifiers. The dataset consists of 10 classes of color images of size $32\\times 32$. Let's build a neural network with **convolutional layers** to classify the images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfGOVAjClVLW"
      },
      "source": [
        "### Download the dataset\n",
        "- Use `request` to download the tar file from [https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)\n",
        "- Use `tarfile` to extract files\n",
        "- Use `pickle` to load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvd_rMKylVOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497d82e6-c584-43d8-9a41-133a4bca3c44"
      },
      "source": [
        "import requests\n",
        "\n",
        "filename = \"cifar-10-python.tar.gz\"\n",
        "if not os.path.isfile(filename):\n",
        "    print(\"Downloading CIFAR10 dataset...\")\n",
        "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    file = requests.get(url)\n",
        "\n",
        "    print(\"Writing to file\", filename, \"...\")\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(file.content)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading CIFAR10 dataset...\n",
            "Writing to file cifar-10-python.tar.gz ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG81Rh39njsY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4b0572-e085-4fe3-a320-afd9c747344e"
      },
      "source": [
        "import tarfile\n",
        "datapath = \"cifar-10-batches-py/\" \n",
        "if not os.path.isdir(datapath):\n",
        "    print(\"Extracting files...\")\n",
        "    tar = tarfile.open(filename)\n",
        "    tar.extractall()\n",
        "    print(\"Files extracted.\")\n",
        "    tar.close()\n",
        "os.listdir(datapath)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting files...\n",
            "Files extracted.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['readme.html',\n",
              " 'batches.meta',\n",
              " 'data_batch_1',\n",
              " 'test_batch',\n",
              " 'data_batch_4',\n",
              " 'data_batch_5',\n",
              " 'data_batch_3',\n",
              " 'data_batch_2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4qtN_Kwnkz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926ce4e2-785e-47cd-8b96-2a8c9f45a413"
      },
      "source": [
        "# load one batch\n",
        "import pickle\n",
        "with open(datapath + \"data_batch_1\", \"rb\") as f:\n",
        "    batch = pickle.load(f, encoding=\"latin1\")\n",
        "    features = batch['data'].reshape([len(batch['data']), 3, 32, 32]).transpose(0, 2, 3, 1)\n",
        "    labels = batch['labels']\n",
        "print(\"feature size:\", features.shape)\n",
        "print(\"label size:\", len(labels))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature size: (10000, 32, 32, 3)\n",
            "label size: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-O9uujRnmGr"
      },
      "source": [
        "The label data is just a list of 10000 numbers in the range 0-9, which corresponds to each of the 10 classes in CIFAR-10. \n",
        "\n",
        "* **airplane**\n",
        "* **automobile**\n",
        "* **bird**\n",
        "* **cat**\n",
        "* **deer**\n",
        "* **dog**\n",
        "* **frog**\n",
        "* **horse**\n",
        "* **ship**\n",
        "* **truck**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbvXzwOgnn7y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "33d6b6c5-b76b-41f7-a70d-907a98dfdee9"
      },
      "source": [
        "# Show a sample image\n",
        "sample_id = 135\n",
        "plt.imshow(features[sample_id])\n",
        "label_names = ['airplane', 'automobile', 'bird',\n",
        "            'cat', 'deer', 'dog', 'frog',\n",
        "            'horse', 'ship', 'truck']\n",
        "plt.xlabel(label_names[labels[sample_id]])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'ship')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_2nNz8CnpN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da76a4d0-6c48-4095-9393-178265072dc6"
      },
      "source": [
        "# Load all images from batch 1-5\n",
        "train_features = np.empty([0, 32, 32, 3], dtype=np.uint8)\n",
        "train_labels = np.empty([0])\n",
        "for k in range(1, 6):\n",
        "    with open(datapath + \"data_batch_\" + str(k), \"rb\") as f:\n",
        "        batch = pickle.load(f, encoding=\"latin1\")\n",
        "        features = batch[\"data\"].reshape([len(batch['data']), 3, 32, 32]).transpose(0, 2, 3, 1)\n",
        "        labels=batch['labels']\n",
        "        print(\"features shape:\", features.shape)\n",
        "        print(\"labels shape:\", len(labels))\n",
        "        train_features = np.append(train_features, features, axis=0)\n",
        "        train_labels = np.append(train_labels, labels, axis=0)\n",
        "print(\"train_features shape:\", train_features.shape)\n",
        "print(\"train_labels shape:\", train_labels.shape)\n",
        "        "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features shape: (10000, 32, 32, 3)\n",
            "labels shape: 10000\n",
            "features shape: (10000, 32, 32, 3)\n",
            "labels shape: 10000\n",
            "features shape: (10000, 32, 32, 3)\n",
            "labels shape: 10000\n",
            "features shape: (10000, 32, 32, 3)\n",
            "labels shape: 10000\n",
            "features shape: (10000, 32, 32, 3)\n",
            "labels shape: 10000\n",
            "train_features shape: (50000, 32, 32, 3)\n",
            "train_labels shape: (50000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xay2mi6LnrEq"
      },
      "source": [
        "## Build CNN model\n",
        "### Create Convolutional Model\n",
        "\n",
        "The entire model consists of 14 layers in total. In addition to layers below lists what techniques are applied to build the model.\n",
        "\n",
        "1. Convolution with 32 different filters in size of (3x3)\n",
        "    - ReLU activation function \n",
        "2. Convolution with 32 different filters in size of (3x3)\n",
        "    - ReLU activation function \n",
        "    - Max Pooling by 2\n",
        "    - Dropout \n",
        "3. Convolution with 64 different filters in size of (3x3)\n",
        "    - ReLU activation function \n",
        "4. Convolution with 64 different filters in size of (3x3)\n",
        "    - ReLU activation function \n",
        "    - Max Pooling by 2\n",
        "    - Dropout \n",
        "5. Flattening the 3-D output of the last convolutional operations.\n",
        "6. Fully Connected Layer with 512 units\n",
        "  - Dropout \n",
        "7. Fully Connected Layer with 10 units (number of image classes)\n",
        "\n",
        "the image below decribes how the conceptual convolving operation differs from the tensorflow implementation when you use [Channel x Width x Height] tensor format. \n",
        "\n",
        "<img src=\"https://adeshpande3.github.io/assets/Cover.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo9fxr9Vntda"
      },
      "source": [
        "batch_size = 32 # How many images to load at a time\n",
        "num_classes = 10 \n",
        "epochs = 10\n",
        "num_predictions = 20"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKz3Lr-3aSxq",
        "outputId": "43fdd5ef-ddc2-4524-f823-ef6234c16997"
      },
      "source": [
        "# The number of training iterations:\n",
        "50000 / 32 * 10"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15625.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtFtokyrnvob"
      },
      "source": [
        "# Build CNN model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\",\n",
        "                              input_shape=features[0].shape, # (32, 32, 3)\n",
        "                              activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\",\n",
        "                              activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\",\n",
        "                              activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\",\n",
        "                              activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "# model.add(tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax))\n",
        "model.add(tf.keras.layers.Dense(num_classes))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rYxSeG_dBft",
        "outputId": "5ff0c72c-36dc-4606-87a0-f4a17a3bbb13"
      },
      "source": [
        "# How can I print the list of layers?\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 2,168,362\n",
            "Trainable params: 2,168,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69mjsLBtnwrM"
      },
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJxxUhQ8nx3h"
      },
      "source": [
        "# Normalize data\n",
        "def normalize(x):\n",
        "    \"\"\"\n",
        "        argument\n",
        "            - x: input image data in numpy array [32, 32, 3]\n",
        "        return\n",
        "            - normalized x \n",
        "    \"\"\"\n",
        "    min_val = np.min(x)\n",
        "    max_val = np.max(x)\n",
        "    x = (x-min_val) / (max_val-min_val)\n",
        "    return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGj02QVnnze3"
      },
      "source": [
        "train_features_scaled = normalize(train_features)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_euMmmhRn0u6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5499db4-f72a-41e0-8776-82cf8c35154d"
      },
      "source": [
        "history =  model.fit(train_features_scaled, train_labels, epochs=10, batch_size=batch_size)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 40s 5ms/step - loss: 1.7707 - accuracy: 0.3490\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.1128 - accuracy: 0.6025\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.9181 - accuracy: 0.6741\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8154 - accuracy: 0.7133\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7568 - accuracy: 0.7357\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6937 - accuracy: 0.7566\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6486 - accuracy: 0.7734\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6160 - accuracy: 0.7819\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5864 - accuracy: 0.7914\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5544 - accuracy: 0.8047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViXUTJNRn1o7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "3130e118-0aa9-4e84-b1e6-fc5ee96553f1"
      },
      "source": [
        "# Evaluate the model\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy') # allocate validation data to get val_accuracy\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0bf65342d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N3j3Jxsn3Tr"
      },
      "source": [
        "# Load test images\n",
        "with open(datapath + \"test_batch\", \"rb\") as f:\n",
        "    batch = pickle.load(f, encoding=\"latin1\")\n",
        "    test_features = batch['data'].reshape([len(batch['data']), 3, 32, 32]).transpose(0, 2, 3, 1)\n",
        "    test_labels = batch['labels']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob0tEPxnn4qT"
      },
      "source": [
        "# Normalize test features\n",
        "test_features_scaled = normalize(test_features)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0l6WS3gn5nX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76bced4c-af5f-4739-8663-2173136d508a"
      },
      "source": [
        "test_labels = np.array(test_labels)\n",
        "test_labels.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrK66WvJn6ig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f221de36-b1bf-4cb7-e8be-83b2cb3b905c"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_features_scaled,  test_labels, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.6607 - accuracy: 0.7752\n",
            "0.7752000093460083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tPiRhSCn7mN"
      },
      "source": [
        "## Addition Discussion: What if we train a dense neural network instead?\n",
        "\n",
        "- Mimic the approach we took in the first neural network example.\n",
        "- Be aware that each color image is represented as a 3D array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QUtqcxfgdEP"
      },
      "source": [
        "# How to evaluate the model in other measures?\n",
        "- Confusion matrix\n",
        "- Cross validation: \n",
        "    - Currently: training: batch 1 - 5, test: test_batch\n",
        "    - Another test: training: batch 1, 2, 3, 4 and test_batch, test: batch 5\n",
        "    - Another test: training: batch 1, 2, 3, 5, and test_batch, test: batch 4\n",
        "    - ...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-inbVVTgw6c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}